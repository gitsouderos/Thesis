{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import forward_diffusion_sample\n",
    "import torch\n",
    "from diffusion import get_time_embedding\n",
    "from diffusion import model_architecture\n",
    "from diffusion import reverse_diffusion_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward diffusion test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_diffusion_steps = 1000\n",
    "betas = torch.linspace(0.0001, 0.02, num_diffusion_steps)\n",
    "\n",
    "batch_size =  4\n",
    "dim = 10\n",
    "\n",
    "x_0 = torch.randn(batch_size, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "betas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep = 50\n",
    "timestep_tensor = torch.full((batch_size,), timestep, dtype=torch.long) # Tensor shaped (batch_size,) with timestep repeated batch_size times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestep_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,noise = forward_diffusion_sample(x_0, timestep_tensor,betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean sample (x_0):\n",
      "tensor([[ 1.4750, -0.3938, -0.4552, -1.6739,  0.8467,  1.0316,  0.9094, -0.4057,\n",
      "         -0.9085, -0.4406],\n",
      "        [ 0.8871,  1.2570, -0.2101, -1.3765,  0.6372,  0.5948, -1.3427,  2.4970,\n",
      "          1.5104,  1.5017],\n",
      "        [ 0.2432,  1.4318, -0.5506,  0.4336,  0.2242, -0.9029,  0.6744,  1.0569,\n",
      "          1.0807,  1.3416],\n",
      "        [ 0.1433,  0.9565, -0.8070,  0.1681, -0.4470,  0.6217,  1.5089,  0.6798,\n",
      "          0.2231, -0.0413]])\n",
      "\n",
      "Noisy sample (x_t):\n",
      "tensor([[ 1.2194, -0.4151, -0.7382, -1.3455,  0.5508,  0.7636,  1.1034, -0.2733,\n",
      "         -1.0079, -0.5609],\n",
      "        [ 0.6060,  1.1153, -0.0248, -1.4095,  0.5671,  0.7894, -1.1267,  2.5681,\n",
      "          1.2953,  1.4257],\n",
      "        [ 0.2092,  1.3063, -0.6171,  0.4502,  0.4828, -0.9745,  0.6418,  1.2699,\n",
      "          0.7880,  1.5301],\n",
      "        [ 0.3794,  1.2219, -0.6230,  0.1375, -0.7460,  0.7359,  1.1333,  0.6272,\n",
      "          0.1124, -0.1248]])\n",
      "\n",
      "Noise added:\n",
      "tensor([[-1.3452, -0.1572, -1.6727,  1.7481, -1.6329, -1.4560,  1.1982,  0.7279,\n",
      "         -0.6524, -0.7324],\n",
      "        [-1.5443, -0.7077,  1.0506, -0.3105, -0.3487,  1.1748,  1.1290,  0.6281,\n",
      "         -1.1086, -0.3070],\n",
      "        [-0.1747, -0.5986, -0.4313,  0.1338,  1.5110, -0.4920, -0.1291,  1.3209,\n",
      "         -1.5943,  1.2043],\n",
      "        [ 1.3743,  1.6142,  0.9907, -0.1618, -1.7635,  0.7135, -2.0350, -0.2438,\n",
      "         -0.6194, -0.4852]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Clean sample (x_0):\")\n",
    "print(x_0)\n",
    "print(\"\\nNoisy sample (x_t):\")\n",
    "print(x_t)\n",
    "print(\"\\nNoise added:\")\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time embedding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_time_embedding(timestep_tensor, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2624,  0.1566, -0.1032,  0.5084, -0.9589,  0.3239,  0.9999,  0.7765,\n",
      "          0.4794,  0.2775,  0.1575,  0.0888,  0.0500,  0.0281,  0.0158,  0.0089,\n",
      "          0.9650, -0.9877, -0.9947, -0.8611,  0.2837, -0.9461, -0.0103,  0.6301,\n",
      "          0.8776,  0.9607,  0.9875,  0.9960,  0.9988,  0.9996,  0.9999,  1.0000],\n",
      "        [-0.2624,  0.1566, -0.1032,  0.5084, -0.9589,  0.3239,  0.9999,  0.7765,\n",
      "          0.4794,  0.2775,  0.1575,  0.0888,  0.0500,  0.0281,  0.0158,  0.0089,\n",
      "          0.9650, -0.9877, -0.9947, -0.8611,  0.2837, -0.9461, -0.0103,  0.6301,\n",
      "          0.8776,  0.9607,  0.9875,  0.9960,  0.9988,  0.9996,  0.9999,  1.0000],\n",
      "        [-0.2624,  0.1566, -0.1032,  0.5084, -0.9589,  0.3239,  0.9999,  0.7765,\n",
      "          0.4794,  0.2775,  0.1575,  0.0888,  0.0500,  0.0281,  0.0158,  0.0089,\n",
      "          0.9650, -0.9877, -0.9947, -0.8611,  0.2837, -0.9461, -0.0103,  0.6301,\n",
      "          0.8776,  0.9607,  0.9875,  0.9960,  0.9988,  0.9996,  0.9999,  1.0000],\n",
      "        [-0.2624,  0.1566, -0.1032,  0.5084, -0.9589,  0.3239,  0.9999,  0.7765,\n",
      "          0.4794,  0.2775,  0.1575,  0.0888,  0.0500,  0.0281,  0.0158,  0.0089,\n",
      "          0.9650, -0.9877, -0.9947, -0.8611,  0.2837, -0.9461, -0.0103,  0.6301,\n",
      "          0.8776,  0.9607,  0.9875,  0.9960,  0.9988,  0.9996,  0.9999,  1.0000]])\n",
      "torch.Size([4, 32])\n"
     ]
    }
   ],
   "source": [
    "print(test)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse diffusion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_T shape: torch.Size([4, 10])\n",
      "time_embedding shape: torch.Size([4, 2])\n",
      "x shape: torch.Size([4, 12])\n"
     ]
    }
   ],
   "source": [
    "x_t_minus_1 = reverse_diffusion_sample(x_t, betas, timestep_tensor, model_architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original sample (x_t): tensor([[ 0.9129,  0.9456,  1.9236,  0.6603,  0.0957, -0.8940,  1.2359,  1.8455,\n",
      "          2.4707, -0.1314],\n",
      "        [ 0.4904,  0.2617, -0.1398, -0.3541,  0.0190,  0.6403,  1.2285,  0.5831,\n",
      "          0.2228,  0.3880],\n",
      "        [-0.7446, -0.3469, -1.2333,  0.9391, -1.0112,  1.4118,  0.7305,  0.3503,\n",
      "         -0.8563,  0.0370],\n",
      "        [ 1.6883,  1.1925, -0.6067, -0.5078, -0.9327, -0.2396,  1.2374, -0.2426,\n",
      "         -0.5686, -0.3173]])\n",
      " Noise added: tensor([[-0.5921,  0.8497,  1.6738,  0.4271, -1.4904, -0.8752, -1.5927, -0.7021,\n",
      "          0.9303,  0.0672],\n",
      "        [-0.7069,  0.5148, -0.2175,  0.2886,  0.1850,  0.9603, -0.7536, -0.7710,\n",
      "          1.1935,  1.2176],\n",
      "        [ 1.0512, -1.2152,  1.1807,  0.4453, -0.5517,  1.9664,  0.4839, -0.1953,\n",
      "          0.0798, -0.0605],\n",
      "        [ 0.0398,  0.3673,  0.4900, -0.7888, -0.4366,  0.5434, -1.3997,  0.6173,\n",
      "         -1.0215, -1.7815]])\n",
      " Reversed sample (x_t-1): tensor([[ 0.9119,  0.9473,  1.9252,  0.6607,  0.0961, -0.8930,  1.2362,  1.8470,\n",
      "          2.4713, -0.1303],\n",
      "        [ 0.4905,  0.2621, -0.1396, -0.3538,  0.0193,  0.6413,  1.2285,  0.5840,\n",
      "          0.2227,  0.3890],\n",
      "        [-0.7446, -0.3468, -1.2338,  0.9402, -1.0112,  1.4118,  0.7300,  0.3505,\n",
      "         -0.8563,  0.0376],\n",
      "        [ 1.6890,  1.1934, -0.6066, -0.5074, -0.9330, -0.2394,  1.2371, -0.2425,\n",
      "         -0.5695, -0.3162]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\" Original sample (x_t): {x_t}\")\n",
    "print(f\" Noise added: {noise}\")\n",
    "print(f\" Reversed sample (x_t-1): {x_t_minus_1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../Datasets'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from custom_dataset import StockDiffusionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../price/raw\"\n",
    "df = pd.read_csv(f\"{base_path}/AAPL.csv\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Daily Return (percentage change from open to close)\n",
    "df['Return'] = (df['Close'] - df['Open']) / df['Open']\n",
    "\n",
    "# 2. Price Difference (Close - Open)\n",
    "df['Diff'] = df['Close'] - df['Open']\n",
    "\n",
    "# 3. High-Low Difference (as a measure of volatility)\n",
    "df['HL_Diff'] = df['High'] - df['Low']\n",
    "\n",
    "# 4. 5-day Moving Average of the Close (shifted to avoid leakage)\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean().shift(1)\n",
    "\n",
    "# 5. 5-day Moving Average of the Return (shifted)\n",
    "df['Return_MA5'] = df['Return'].rolling(window=5).mean().shift(1)\n",
    "\n",
    "# Drop rows with NaN values that result from rolling and shifting\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Diff</th>\n",
       "      <th>HL_Diff</th>\n",
       "      <th>MA5</th>\n",
       "      <th>Return_MA5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-09-11</td>\n",
       "      <td>95.015717</td>\n",
       "      <td>95.728569</td>\n",
       "      <td>93.785713</td>\n",
       "      <td>94.370003</td>\n",
       "      <td>85.265068</td>\n",
       "      <td>125995800</td>\n",
       "      <td>-0.006796</td>\n",
       "      <td>-0.645714</td>\n",
       "      <td>1.942856</td>\n",
       "      <td>96.132857</td>\n",
       "      <td>-0.002394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-09-12</td>\n",
       "      <td>95.264282</td>\n",
       "      <td>95.699997</td>\n",
       "      <td>93.714287</td>\n",
       "      <td>95.684288</td>\n",
       "      <td>86.452538</td>\n",
       "      <td>178058300</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.420006</td>\n",
       "      <td>1.985710</td>\n",
       "      <td>95.722000</td>\n",
       "      <td>-0.006519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-09-13</td>\n",
       "      <td>96.767143</td>\n",
       "      <td>97.928574</td>\n",
       "      <td>96.395714</td>\n",
       "      <td>97.568573</td>\n",
       "      <td>88.155037</td>\n",
       "      <td>149590000</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.801430</td>\n",
       "      <td>1.532860</td>\n",
       "      <td>95.709428</td>\n",
       "      <td>-0.004057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-09-14</td>\n",
       "      <td>98.565712</td>\n",
       "      <td>99.568573</td>\n",
       "      <td>98.269997</td>\n",
       "      <td>98.754288</td>\n",
       "      <td>89.226341</td>\n",
       "      <td>150118500</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.188576</td>\n",
       "      <td>1.298576</td>\n",
       "      <td>95.901143</td>\n",
       "      <td>-0.003321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-09-17</td>\n",
       "      <td>99.907143</td>\n",
       "      <td>99.971428</td>\n",
       "      <td>99.230003</td>\n",
       "      <td>99.968575</td>\n",
       "      <td>90.323479</td>\n",
       "      <td>99507800</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>0.741425</td>\n",
       "      <td>96.210858</td>\n",
       "      <td>-0.003644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date       Open       High        Low      Close  Adj Close  \\\n",
       "0  2012-09-11  95.015717  95.728569  93.785713  94.370003  85.265068   \n",
       "1  2012-09-12  95.264282  95.699997  93.714287  95.684288  86.452538   \n",
       "2  2012-09-13  96.767143  97.928574  96.395714  97.568573  88.155037   \n",
       "3  2012-09-14  98.565712  99.568573  98.269997  98.754288  89.226341   \n",
       "4  2012-09-17  99.907143  99.971428  99.230003  99.968575  90.323479   \n",
       "\n",
       "      Volume    Return      Diff   HL_Diff        MA5  Return_MA5  \n",
       "0  125995800 -0.006796 -0.645714  1.942856  96.132857   -0.002394  \n",
       "1  178058300  0.004409  0.420006  1.985710  95.722000   -0.006519  \n",
       "2  149590000  0.008282  0.801430  1.532860  95.709428   -0.004057  \n",
       "3  150118500  0.001913  0.188576  1.298576  95.901143   -0.003321  \n",
       "4   99507800  0.000615  0.061432  0.741425  96.210858   -0.003644  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['Open', 'High', 'Low', 'Volume', 'Return', 'Diff', 'HL_Diff', 'MA5', 'Return_MA5']\n",
    "# We keep the target as the raw 'Close' (normalized later)\n",
    "target_column = 'Close'\n",
    "\n",
    "filtered_df = df[feature_columns + [target_column]]\n",
    "\n",
    "seq_len = 10\n",
    "\n",
    "# Split into training and test data \n",
    "train_size = int(len(filtered_df) * 0.8)\n",
    "train_data = filtered_df.iloc[:train_size].copy()\n",
    "test_data = filtered_df.iloc[train_size:].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "      <th>Diff</th>\n",
       "      <th>HL_Diff</th>\n",
       "      <th>MA5</th>\n",
       "      <th>Return_MA5</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>95.015717</td>\n",
       "      <td>95.728569</td>\n",
       "      <td>93.785713</td>\n",
       "      <td>125995800</td>\n",
       "      <td>-0.006796</td>\n",
       "      <td>-0.645714</td>\n",
       "      <td>1.942856</td>\n",
       "      <td>96.132857</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>94.370003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.264282</td>\n",
       "      <td>95.699997</td>\n",
       "      <td>93.714287</td>\n",
       "      <td>178058300</td>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.420006</td>\n",
       "      <td>1.985710</td>\n",
       "      <td>95.722000</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>95.684288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.767143</td>\n",
       "      <td>97.928574</td>\n",
       "      <td>96.395714</td>\n",
       "      <td>149590000</td>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.801430</td>\n",
       "      <td>1.532860</td>\n",
       "      <td>95.709428</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>97.568573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98.565712</td>\n",
       "      <td>99.568573</td>\n",
       "      <td>98.269997</td>\n",
       "      <td>150118500</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.188576</td>\n",
       "      <td>1.298576</td>\n",
       "      <td>95.901143</td>\n",
       "      <td>-0.003321</td>\n",
       "      <td>98.754288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>99.907143</td>\n",
       "      <td>99.971428</td>\n",
       "      <td>99.230003</td>\n",
       "      <td>99507800</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.061432</td>\n",
       "      <td>0.741425</td>\n",
       "      <td>96.210858</td>\n",
       "      <td>-0.003644</td>\n",
       "      <td>99.968575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>106.620003</td>\n",
       "      <td>107.440002</td>\n",
       "      <td>106.290001</td>\n",
       "      <td>24970300</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.199997</td>\n",
       "      <td>1.150001</td>\n",
       "      <td>107.980000</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>106.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>105.800003</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>105.500000</td>\n",
       "      <td>24863900</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.199997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>107.642000</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>106.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>105.660004</td>\n",
       "      <td>106.570000</td>\n",
       "      <td>105.639999</td>\n",
       "      <td>29662400</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.439994</td>\n",
       "      <td>0.930001</td>\n",
       "      <td>107.072000</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>106.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>106.139999</td>\n",
       "      <td>106.800003</td>\n",
       "      <td>105.620003</td>\n",
       "      <td>26701500</td>\n",
       "      <td>0.005559</td>\n",
       "      <td>0.590004</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>106.686000</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>106.730003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>107.699997</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>106.820000</td>\n",
       "      <td>26802500</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.030006</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>106.518001</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>107.730003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1002 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High         Low     Volume    Return      Diff  \\\n",
       "0      95.015717   95.728569   93.785713  125995800 -0.006796 -0.645714   \n",
       "1      95.264282   95.699997   93.714287  178058300  0.004409  0.420006   \n",
       "2      96.767143   97.928574   96.395714  149590000  0.008282  0.801430   \n",
       "3      98.565712   99.568573   98.269997  150118500  0.001913  0.188576   \n",
       "4      99.907143   99.971428   99.230003   99507800  0.000615  0.061432   \n",
       "...          ...         ...         ...        ...       ...       ...   \n",
       "997   106.620003  107.440002  106.290001   24970300  0.001876  0.199997   \n",
       "998   105.800003  106.500000  105.500000   24863900  0.001890  0.199997   \n",
       "999   105.660004  106.570000  105.639999   29662400  0.004164  0.439994   \n",
       "1000  106.139999  106.800003  105.620003   26701500  0.005559  0.590004   \n",
       "1001  107.699997  108.000000  106.820000   26802500  0.000279  0.030006   \n",
       "\n",
       "       HL_Diff         MA5  Return_MA5       Close  \n",
       "0     1.942856   96.132857   -0.002394   94.370003  \n",
       "1     1.985710   95.722000   -0.006519   95.684288  \n",
       "2     1.532860   95.709428   -0.004057   97.568573  \n",
       "3     1.298576   95.901143   -0.003321   98.754288  \n",
       "4     0.741425   96.210858   -0.003644   99.968575  \n",
       "...        ...         ...         ...         ...  \n",
       "997   1.150001  107.980000   -0.001699  106.820000  \n",
       "998   1.000000  107.642000   -0.000681  106.000000  \n",
       "999   0.930001  107.072000   -0.000781  106.099998  \n",
       "1000  1.180000  106.686000    0.001046  106.730003  \n",
       "1001  1.180000  106.518001    0.001823  107.730003  \n",
       "\n",
       "[1002 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57825/3772158868.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.32072709 0.46856191 0.38772434 ... 0.0471822  0.03877453 0.03906133]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  train_data.loc[:, train_data.columns] = scaler.transform(train_data)\n",
      "/tmp/ipykernel_57825/3772158868.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[ 0.03928253  0.08325006  0.1134565   0.0951555   0.09156573  0.13950723\n",
      "  0.27782951  0.21846813  0.1897979   0.09647874  0.06095948  0.06518731\n",
      "  0.05119053  0.11197765  0.04776999  0.0328282   0.04712172  0.06485735\n",
      "  0.0662547   0.02457757  0.04739346  0.02387137  0.04467458  0.03212115\n",
      "  0.06584836  0.14480245  0.06968404  0.06288499  0.06419062  0.03003833\n",
      "  0.03267515  0.01984344  0.03146067  0.02881107  0.02979356  0.0996193\n",
      "  0.15074622  0.06109493  0.07046464  0.03797349  0.08740009  0.04340359\n",
      "  0.03943076  0.05051755  0.05541012  0.03125821  0.1309891   0.125191\n",
      "  0.0597663   0.10827003  0.05457103  0.13003529  0.04141675  0.0436796\n",
      "  0.04605262  0.03668462  0.04083294 -0.00445954  0.04017302  0.04396327\n",
      "  0.06563909  0.06826455  0.03828187  0.06042053  0.03733772  0.04813715\n",
      "  0.03981609  0.0606423   0.03784571  0.08713885  0.05958939  0.09506322\n",
      "  0.08889171  0.0418353   0.02379157  0.03048783  0.0370265   0.00322234\n",
      "  0.01490913  0.02231756  0.00565954  0.04980567  0.04468196  0.02292011\n",
      "  0.02597406  0.05311547  0.05825508  0.03241561  0.04129351  0.03986692\n",
      "  0.03710033  0.06074794  0.0302885   0.03563909  0.05551774  0.02556687\n",
      "  0.02886304  0.05489219  0.03774122  0.02134359  0.04921277  0.10266331\n",
      "  0.28094252  0.05867676  0.03254396  0.03918457  0.07137926  0.02827553\n",
      "  0.04345527  0.01993119  0.02836441  0.05730184  0.06410799  0.02708433\n",
      "  0.02598712  0.03254368  0.02212163  0.02198334  0.02478996  0.0204761\n",
      "  0.02963511  0.06635551  0.03738173  0.02289172  0.02471443  0.0124938\n",
      "  0.01607421  0.02586701  0.01864572  0.01242395  0.00642508  0.03590743\n",
      "  0.01756441  0.08756819  0.0241238   0.0752016   0.03638561  0.02072854\n",
      "  0.02654765  0.02989692  0.0577238   0.04584079  0.0231734   0.01878457\n",
      "  0.01970459  0.01943682  0.04166067  0.02300785  0.01029569  0.01671652\n",
      "  0.04921817  0.02073904  0.01356318  0.01003985  0.0046884   0.01215901\n",
      "  0.02917141  0.01213772  0.01160786  0.01654075  0.01986218  0.00340719\n",
      "  0.02218836  0.0583715   0.0917344   0.09271348  0.02931992  0.04055267\n",
      "  0.10138948  0.0740672   0.03623085  0.04034652  0.05531642  0.03681012\n",
      "  0.01988291  0.10711206  0.05827297  0.03951083  0.02816848  0.01951491\n",
      "  0.01741107  0.01757463  0.02457558  0.02010554  0.03238466  0.00953441\n",
      "  0.0418106   0.0348849   0.03855702  0.02278239  0.02329692  0.14719251\n",
      "  0.16827514  0.05996876  0.05248878  0.05428963  0.10595749  0.05535731\n",
      "  0.03365934  0.02333952  0.01720748  0.06358636  0.03590913  0.03326692\n",
      "  0.0256583   0.05239848  0.02833232  0.00344127  0.02420217  0.03146919\n",
      "  0.01747837  0.02284202  0.0191256   0.03361505  0.03450923  0.0201203\n",
      "  0.03051708  0.01369352  0.02236611  0.0119185   0.03749985  0.02398523\n",
      "  0.01649077  0.00776507  0.05517245  0.01183332  0.01930762  0.06338532\n",
      "  0.16154395  0.03989843  0.02133507  0.02505603  0.06576289  0.03715598\n",
      "  0.07882034  0.03751263  0.0255044   0.04662309  0.0415292   0.04229304\n",
      "  0.04083776  0.03782896  0.02430156  0.0180389   0.01923095  0.03530629\n",
      "  0.03668604  0.04676904  0.04038769  0.03901192  0.00995665]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_data.loc[:, test_data.columns] = scaler.transform(test_data)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data)\n",
    "\n",
    "# Transform train and test sets.\n",
    "train_data.loc[:, train_data.columns] = scaler.transform(train_data)\n",
    "test_data.loc[:, test_data.columns] = scaler.transform(test_data)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = StockDiffusionDataset(train_data, target_column=target_column)\n",
    "test_dataset = StockDiffusionDataset(test_data, target_column=target_column)\n",
    "print(\"Datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4997])\n"
     ]
    }
   ],
   "source": [
    "#Visualize the first sample\n",
    "sample = train_dataset[0]\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1])\n"
     ]
    }
   ],
   "source": [
    "for x0 in train_loader :\n",
    "    # print(x0)\n",
    "    print(x0.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import model_architecture\n",
    "from diffusion import forward_diffusion_sample\n",
    "from diffusion import reverse_diffusion_sample\n",
    "\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.47396522760391235\n",
      "Epoch 2, Loss: 0.5742954015731812\n",
      "Epoch 3, Loss: 0.5933837890625\n",
      "Epoch 4, Loss: 0.7202255725860596\n",
      "Epoch 5, Loss: 0.34455788135528564\n",
      "Epoch 6, Loss: 0.21193692088127136\n",
      "Epoch 7, Loss: 0.23508334159851074\n",
      "Epoch 8, Loss: 0.49866870045661926\n",
      "Epoch 9, Loss: 0.1860816478729248\n",
      "Epoch 10, Loss: 0.4293581247329712\n",
      "Epoch 11, Loss: 0.5209160447120667\n",
      "Epoch 12, Loss: 0.3300785422325134\n",
      "Epoch 13, Loss: 0.2333860993385315\n",
      "Epoch 14, Loss: 0.5953035950660706\n",
      "Epoch 15, Loss: 0.22856773436069489\n",
      "Epoch 16, Loss: 0.24293376505374908\n",
      "Epoch 17, Loss: 0.24218028783798218\n",
      "Epoch 18, Loss: 0.27146539092063904\n",
      "Epoch 19, Loss: 0.31763091683387756\n",
      "Epoch 20, Loss: 0.4374973177909851\n",
      "Epoch 21, Loss: 0.31849151849746704\n",
      "Epoch 22, Loss: 0.42059147357940674\n",
      "Epoch 23, Loss: 0.28873878717422485\n",
      "Epoch 24, Loss: 0.2215581089258194\n",
      "Epoch 25, Loss: 0.761014461517334\n",
      "Epoch 26, Loss: 0.22949521243572235\n",
      "Epoch 27, Loss: 0.4238676130771637\n",
      "Epoch 28, Loss: 0.505625307559967\n",
      "Epoch 29, Loss: 0.3161892592906952\n",
      "Epoch 30, Loss: 0.16825523972511292\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_diffusion_steps = 100  # Total diffusion steps\n",
    "num_epochs = 30\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Create a beta schedule: linearly spaced between 0.0001 and 0.02\n",
    "betas = torch.linspace(0.0001, 0.02, num_diffusion_steps)\n",
    "\n",
    "# Since our targets are scalars, dim = 1\n",
    "dim = 1\n",
    "embedding_dim = 32  # As used in get_time_embedding\n",
    "# Instantiate the denoising network\n",
    "denoise_net = model_architecture(dim, embedding_dim, hidden_size=256)\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(denoise_net.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x0 in train_loader:  # x0 has shape [batch_size] or [batch_size, 1]\n",
    "        # If necessary, reshape x0 to [batch_size, dim] (here dim might be 1)\n",
    "        # x0 = x0.unsqueeze(1)  if it's a scalar\n",
    "        # print(x0.shape)\n",
    "        \n",
    "        # Sample a random diffusion timestep for each sample in the batch\n",
    "        t = torch.randint(0, num_diffusion_steps, (batch_size,), dtype=torch.long)\n",
    "        # print(t.shape)\n",
    "        \n",
    "        # Generate the noisy sample and the true noise using forward diffusion\n",
    "        x_t, true_noise = forward_diffusion_sample(x0, t, betas)\n",
    "        \n",
    "        # Use the reverse diffusion function to predict the noise\n",
    "        predicted_noise = reverse_diffusion_sample(x_t, betas, t, embedding_dim, denoise_net)\n",
    "        \n",
    "        # Compute the loss (MSE between predicted noise and true noise)\n",
    "        loss = F.mse_loss(predicted_noise, true_noise)\n",
    "        \n",
    "        # Backpropagate and update the network parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
